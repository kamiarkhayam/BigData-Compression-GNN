# Graph Neural Networks for Precision-Guaranteed Compression of Big Data

This GitHub repository contains the source code and datasets utilized in the research paper, "Graph Neural Networks for Precision-Guaranteed Compression of Big Data," presented at the IEEE Big Data Conference 2024. The paper introduces a transformative approach to data compression using Graph Neural Networks (GNNs), specifically designed to ensure high precision during decompression. This methodology effectively addresses the challenges of managing vast data volumes generated by smart infrastructure systems while maintaining strict accuracy standards crucial for operational integrity and reliability.

### Key Contributions

- **Precision-Guaranteed Compression**: Employs advanced GNN models to deliver compression with guaranteed precision in decompression, crucial for applications where data fidelity is paramount.
- **Efficient Data Management**: Demonstrates the capability to handle and compress large-scale datasets from diverse sources such as traffic data, smart meter energy consumption, and renewable power generation, thereby reducing the storage and management burden significantly.
- **Superior Performance**: Outperforms traditional and other prediction-based compression methods, showcasing superior accuracy and efficiency through the innovative use of GNNs over other deep learning models.

## Repository Structure

- `data_processing/`: Scripts and utilities for preprocessing and setting up datasets.
  - `data_cleaning/`: Contains scripts for data cleaning across three distinct datasets.
  - `data_generation/`: Scripts for generating training, validation, and test datasets in formats suitable for graph, CNN, and LSTM models.
- `models/`: Houses class files and training scripts for the deep learning models utilized in the project.
- `plotting/`: Scripts for visualization of data and results.
  - `map_plotting/`: Scripts for generating spatial overview maps of datasets.
  - `results_plotting/`: Scripts for plotting the results of data compression and model performance.
- `compression/`: Contains Python scripts for data compression using DL models and traditional methods for three datasets, along with utility functions.


## Getting Started

1. **Setup**
   - Ensure Python 3.x is installed on your system.
   - Clone this repository using:
     ```
     git clone <repository-url>
     ```
   - Install required Python packages:
     ```
     pip install -r requirements.txt
     ```

2. **Download the Data**
   - **NREL Dataset**: Available [here](https://www.nrel.gov/grid/solar-power-data.html). Synthetic solar photovoltaic (PV) power plant data points for the United States for the year 2006.
   - **Caltrans Data**: Available through [Caltrans PeMS dashboards](https://pems.dot.ca.gov/?dnode=Clearinghouse&type=station_5min&district_id=7&submit=Submit).
   - **ComEd Dataset**: Contact ComEd to purchase smart meter data.

3. **Data Preparation**
   - Start by cleaning the data using scripts in the `data_cleaning` directory.
   - Prepare the data in the required formats for different DL model training using scripts in the `data_generation` directory.

4. **Model Training**
   - Proceed to the `models` folder to train various models using the provided scripts.

5. **Data Compression**
   - Utilize the trained models and prepared data to perform compression in the `compression` folder.

## Requirements

- Python 3.x
- PyTorch
- PyTorch Geometric
- numpy
- pywt
- zfpy
- sklearn
- scipy
- pandas
- matplotlib
- geopandas
- folium
- shapely
- fitz
- PTL

## License

This project is open-sourced under the MIT License. See the LICENSE file for more details.

## Citation
If you use this code or the framework in your research, please cite our paper:
Khayambashi, K., & Alemazkoor, N. (2024). Graph neural networks for precision-guaranteed compression of large-scale spatial data. In Proceedings of the IEEE Big Data Conference. IEEE.
